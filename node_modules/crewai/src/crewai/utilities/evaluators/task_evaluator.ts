import { ChatOpenAI } from 'langchain/chat_models/openai';
import z from 'zod';
import { Converter } from '../converter';
import { PydanticSchemaParser } from '../pydantic_schema_parser';

// Mock agentops provider
function mockAgentOpsProvider() {
  return function trackAgent() {
    return function (f) {
      return f;
    };
  };
}

const agentops = process.env.AGENTOPS_API_KEY ? require('agentops').trackAgent : mockAgentOpsProvider();

const Entity = z.object({
  name: z.string().describe("The name of the entity."),
  type: z.string().describe("The type of the entity."),
  description: z.string().describe("Description of the entity."),
  relationships: z.array(z.string()).describe("Relationships of the entity.")
});

const TaskEvaluation = z.object({
  suggestions: z.array(z.string()).describe("Suggestions to improve future similar tasks."),
  quality: z.number().describe("A score from 0 to 10 evaluating on completion, quality, and overall performance, all taking into account the task description, expected output, and the result of the task."),
  entities: z.array(Entity).describe("Entities extracted from the task output.")
});

const TrainingTaskEvaluation = z.object({
  suggestions: z.array(z.string()).describe("Based on the Human Feedbacks and the comparison between Initial Outputs and Improved outputs provide action items based on human_feedback for future tasks."),
  quality: z.number().describe("A score from 0 to 10 evaluating on completion, quality, and overall performance from the improved output to the initial output based on the human feedback."),
  final_summary: z.string().describe("A step by step action items to improve the next Agent based on the human-feedback and improved output.")
});

class TaskEvaluator {
  constructor(originalAgent) {
    this.llm = originalAgent.llm;
  }

  @agentops({ name: "Task Evaluator" })
  async evaluate(task, output) {
    const evaluationQuery = `Assess the quality of the task completed based on the description, expected output, and actual results.

Task Description:
${task.description}

Expected Output:
${task.expected_output}

Actual Output:
${output}

Please provide:
- Bullet points suggestions to improve future similar tasks
- A score from 0 to 10 evaluating on completion, quality, and overall performance
- Entities extracted from the task output, if any, their type, description, and relationships`;

    let instructions = "Convert all responses into valid JSON output.";

    if (!this._isGpt(this.llm)) {
      const modelSchema = new PydanticSchemaParser(TaskEvaluation).getSchema();
      instructions = `${instructions}\n\nReturn only valid JSON with the following schema:\n\`\`\`json\n${modelSchema}\n\`\`\``;
    }

    const converter = new Converter({
      llm: this.llm,
      text: evaluationQuery,
      model: TaskEvaluation,
      instructions: instructions,
    });

    return converter.toPydantic();
  }

  _isGpt(llm) {
    return llm instanceof ChatOpenAI && llm.openai_api_base === null;
  }

  async evaluateTrainingData(trainingData, agentId) {
    const outputTrainingData = trainingData[agentId];

    let finalAggregatedData = "";
    for (const [_, data] of Object.entries(outputTrainingData)) {
      finalAggregatedData += `Initial Output:\n${data.initial_output}\n\n` +
        `Human Feedback:\n${data.human_feedback}\n\n` +
        `Improved Output:\n${data.improved_output}\n\n`;
    }

    const evaluationQuery = `Assess the quality of the training data based on the llm output, human feedback , and llm output improved result.

${finalAggregatedData}
Please provide:
- Based on the Human Feedbacks and the comparison between Initial Outputs and Improved outputs provide action items based on human_feedback for future tasks
- A score from 0 to 10 evaluating on completion, quality, and overall performance from the improved output to the initial output based on the human feedback`;

    let instructions = "I'm gonna convert this raw text into valid JSON.";

    if (!this._isGpt(this.llm)) {
      const modelSchema = new PydanticSchemaParser(TrainingTaskEvaluation).getSchema();
      instructions = `${instructions}\n\nThe json should have the following structure, with the following keys:\n${modelSchema}`;
    }

    const converter = new Converter({
      llm: this.llm,
      text: evaluationQuery,
      model: TrainingTaskEvaluation,
      instructions: instructions,
    });

    return converter.toPydantic();
  }
}

export { TaskEvaluator, TaskEvaluation, TrainingTaskEvaluation };